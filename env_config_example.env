# LLM Provider Configuration
# =========================
# Supported providers: ollama, groq_cloud, openai, google_gemini, huggingface
LLM_PROVIDER=huggingface

# Ollama Configuration
# ===================
OLLAMA_API_URL=http://localhost:11434
OLLAMA_PRIMARY_MODEL=llama3.2:3b
OLLAMA_BACKUP_MODEL=qwen2.5:3b
OLLAMA_FALLBACK_MODEL=qwen:4b
OLLAMA_TEMPERATURE=0.1
OLLAMA_MAX_CONTEXT_LENGTH=8000

# Groq Cloud Configuration
# ========================
GROQ_API_KEYS=your_groq_key_1,your_groq_key_2,your_groq_key_3
GROQ_PRIMARY_MODEL=gemma2-9b-it
GROQ_BACKUP_MODEL=llama-3.1-70b-versatile
GROQ_FALLBACK_MODEL=mixtral-8x7b-32768
GROQ_TEMPERATURE=0.1
GROQ_MAX_TOKENS=1024
GROQ_MAX_CONTEXT_LENGTH=8000

# OpenAI Configuration
# ===================
OPENAI_API_KEYS=your_openai_key_1,your_openai_key_2
# Alternative single key format:
# OPENAI_API_KEY=your_openai_key
OPENAI_ORGANIZATION=your_org_id  # Optional
OPENAI_PRIMARY_MODEL=gpt-3.5-turbo
OPENAI_BACKUP_MODEL=gpt-3.5-turbo-instruct
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=1024
OPENAI_MAX_CONTEXT_LENGTH=8000

# Google Gemini Configuration
# ===========================
GOOGLE_API_KEYS=your_google_key_1,your_google_key_2
# Alternative single key format:
# GOOGLE_API_KEY=your_google_key
GOOGLE_PRIMARY_MODEL=gemini-1.5-flash
GOOGLE_BACKUP_MODEL=gemini-1.5-pro
GOOGLE_FALLBACK_MODEL=gemini-pro
GOOGLE_TEMPERATURE=0.1
GOOGLE_MAX_TOKENS=1024
GOOGLE_TOP_K=40
GOOGLE_MAX_CONTEXT_LENGTH=8000

# Hugging Face Configuration
# ==========================
HUGGINGFACE_MODEL_ID=microsoft/Phi-3-mini-4k-instruct
HUGGINGFACE_TASK=text-generation
HUGGINGFACE_DEVICE=auto  # or 'cpu', 'cuda', 'cuda:0', etc.
HUGGINGFACE_TEMPERATURE=0.1
HUGGINGFACE_MAX_NEW_TOKENS=1024
HUGGINGFACE_TOP_K=50
HUGGINGFACE_TOP_P=0.8
HUGGINGFACE_MAX_CONTEXT_LENGTH=4000
HUGGINGFACE_TRUST_REMOTE_CODE=false
HUGGINGFACE_TOKEN=your_hf_token  # Optional, for private models

# Other configurations...
GROQ_API_KEY=your_legacy_groq_key  # Legacy support
